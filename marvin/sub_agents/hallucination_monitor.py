# sub_agents/hallucination_monitor.py

import logging
import threading
from modules.machine_learning.ml_module import MachineLearningModule
from modules.security.input_sanitatizaton import InputSanitizer
from modules.utilities.logging_manager import setup_logging

class HallucinationMonitor:
    """
    Monitors agent outputs to detect hallucinations or unwanted behavior.
    """

    def __init__(self, shared_memory, communication_module):
        self.name = 'HallucinationMonitor'
        self.shared_memory = shared_memory
        self.communication_module = communication_module
        self.ml_module = MachineLearningModule()
        self.logger = setup_logging(self.name)
        self.lock = threading.Lock()
        self.logger.info(f"{self.name} initialized successfully.")

    def monitor_output(self, agent_id, agent_output):
        """
        Analyzes agent output to detect hallucinations.

        Args:
            agent_id (str): Identifier of the agent producing the output.
            agent_output (str): The output generated by the agent.

        Returns:
            bool: True if hallucination detected, False otherwise.
        """
        try:
            sanitized_output = sanitized_output(agent_output)
            self.logger.debug(f"Sanitized output from agent {agent_id}: {sanitized_output}")

            # Use advanced NLP and ML techniques to detect hallucinations
            is_hallucination = self.ml_module.detect_hallucination(sanitized_output)
            self.logger.debug(f"Hallucination detection result for agent {agent_id}: {is_hallucination}")

            if is_hallucination:
                self.logger.warning(f"Hallucination detected in output from agent {agent_id}.")
                self.handle_hallucination(agent_id, sanitized_output)
                return True
            else:
                self.logger.info(f"No hallucination detected in output from agent {agent_id}.")
                return False
        except Exception as e:
            self.logger.error(f"Error monitoring output from agent {agent_id}: {e}", exc_info=True)
            return False

    def handle_hallucination(self, agent_id, sanitized_output):
        """
        Handles detected hallucinations by notifying the agent and logging the incident.

        Args:
            agent_id (str): Identifier of the agent.
            sanitized_output (str): The sanitized output that contains hallucination.
        """
        try:
            self.logger.info(f"Handling hallucination from agent {agent_id}.")

            # Notify the agent to revise its output
            self.communication_module.send_message(
                sender_id=self.name,
                receiver_id=agent_id,
                message_type='hallucination_alert',
                content='Hallucination detected in your output. Please revise.'
            )
            self.logger.debug(f"Sent hallucination alert to agent {agent_id}.")

            # Log the incident in shared memory
            with self.lock:
                hallucination_log = self.shared_memory.read_data('hallucination_logs') or []
                hallucination_log.append({
                    'agent_id': agent_id,
                    'output': sanitized_output,
                    'timestamp': self.get_current_timestamp()
                })
                self.shared_memory.write_data('hallucination_logs', hallucination_log)
            self.logger.debug("Hallucination incident logged successfully.")
        except Exception as e:
            self.logger.error(f"Error handling hallucination from agent {agent_id}: {e}", exc_info=True)

    @staticmethod
    def get_current_timestamp():
        """
        Returns the current timestamp.

        Returns:
            str: Current timestamp in ISO format.
        """
        from datetime import datetime
        return datetime.utcnow().isoformat()
